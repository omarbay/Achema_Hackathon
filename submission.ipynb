{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e8849c",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be38660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, accuracy_score\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f01be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following command to install additional packages\n",
    "# !{sys.executable} -m pip install PACKAGENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8cad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load additionaly installed packages\n",
    "# import PACKAGENAME\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1af590",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef1048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file path to the data\n",
    "val_dir = './data/ValidationData'\n",
    "\n",
    "# Create lists containing all image paths\n",
    "val_normal = [os.path.join(val_dir, 'good/{}').format(i) for i in os.listdir(os.path.join(val_dir, 'good'))]\n",
    "val_fluten = [os.path.join(val_dir, 'bad/{}').format(i) for i in os.listdir(os.path.join(val_dir, 'bad'))]\n",
    "val_images = val_normal + val_fluten\n",
    "np.random.shuffle(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f55c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Due to the limited memory size, not all images can be loaded at once.\n",
    "# We select only 100 images\n",
    "val_images = val_images[0:100]\n",
    "\n",
    "# Add your preprocessing steps here\n",
    "##### MODIFY ACCORDING TO THE MODEL ######\n",
    "# As shown in the attached .py and the report\n",
    "# we opted to used the keras-tuner tool for finding\n",
    "# the best parameters.\n",
    "# We also preferred to work with smaller images\n",
    "# to reduce the number of parameters of the CNN model\n",
    "# The main goal is to find an optimal point\n",
    "# between accuraccy and inference time\n",
    "# The parameters will be better understood on the \n",
    "# following lines of code\n",
    "vertical_trim = 50\n",
    "horizonta_trim = 80\n",
    "img_width = 60\n",
    "img_height = img_width * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce511f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create empty list which will hold the images\n",
    "### We opted for storing the image in a  numpy array, since it is\n",
    "### easier to handle the data and memory effective\n",
    "X = np.zeros((len(val_images), img_height, img_width, 1), dtype=float)\n",
    "\n",
    "# Create empty list which will hold the labels\n",
    "y_true = []\n",
    "\n",
    "# Loop over all image paths to read each image and their corresponding true label\n",
    "for i, image in enumerate(val_images):\n",
    "    # Ignore .ipynb-checkpoint files\n",
    "    if 'ipynb' in image:\n",
    "        continue\n",
    "    ##### !!!!!!   VERY IMPORTANT !!!!!!! #####\n",
    "    #### since we are using cv2 functions #####\n",
    "    #### it is necessary to resize, trim  #####\n",
    "    #### and apply the inversion function #####\n",
    "\n",
    "    # Read the image\n",
    "    # We are using grayscale images, single-channel,\n",
    "    # Therefore we are loading witht the \"0\" flag\n",
    "    img = cv2.imread(image,0)\n",
    "\n",
    "    # Vertical and Horizontal trim from the original dataset\n",
    "    # While the training the CNN, we noticed that the camera\n",
    "    # positioning affected the acc. results. Hence, we decide\n",
    "    # to remove the background from the original images\n",
    "    img_trim = img[vertical_trim:-vertical_trim,horizonta_trim:-horizonta_trim]\n",
    "\n",
    "    # As we reduce the size of the images, we noted that\n",
    "    # some Fluten example with large bubbles were missclas-\n",
    "    # sifed. Analyzing the results, we observed that when\n",
    "    # the images were rescaled, the small gas-liquid inter-\n",
    "    # faces (pixel values between 0 and 20) lost their reso-\n",
    "    # lution. When the image went to a max-pooling layer,\n",
    "    # this information completely was lost. Thus, in order to\n",
    "    # keep this information, we inverted the image\n",
    "    # (cv2.bitwise_not function). Then, this information would\n",
    "    # not be lost in the max-pooling layer\n",
    "    img_bit = cv2.bitwise_not(img_trim)\n",
    "\n",
    "    # Image dimensions used wilhe training the CNNs\n",
    "    # In order to reduced the number of parameter on the\n",
    "    # CNN, the image must be reduced. The idea is to find\n",
    "    # an optimal point between acc and inference time\n",
    "    img_resized = cv2.resize(img_bit, (img_width, img_height))\n",
    "    img_resized = img_resized.astype(float)\n",
    "\n",
    "    # Uncomment if debugging is necessary. It is interisting\n",
    "    # to check the reduced images with the inversion filter\n",
    "    # cv2.imshow(\"debug\", img_resized); cv2.waitKey(0) ### uncomment for debug\n",
    "    # print(i)\n",
    "\n",
    "    X[i,:,:,0] = img_resized\n",
    "\n",
    "    # X.append(img_resized)\n",
    "\n",
    "    # Load the true label\n",
    "    if 'fluten' in image:\n",
    "        y_true.append(1.0)\n",
    "    elif 'normal' in image:\n",
    "        y_true.append(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae2813",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e07d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "971c14e5",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49169a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained model here\n",
    "#model = keras.models.load_model('best_model_40_80_True_02.h5', compile = True)\n",
    "model = keras.models.load_model('best_model_60_120_True_00.h5', compile = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fdc8b",
   "metadata": {},
   "source": [
    "## Predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2747c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.407 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Start the timer to measure the computation time needed for inference (please do not modify the following line)\n",
    "start_time = time.time()\n",
    "\n",
    "# Use your loaded model to make a prediction of the label of each image\n",
    "y_pred_probs = model.predict(X)\n",
    "\n",
    "# End timer (please do not modify the following line)\n",
    "comp_time = round((time.time() - start_time),3)\n",
    "print(\"--- %s seconds ---\" % comp_time)\n",
    "\n",
    "# Transform probabilities to labels\n",
    "y_pred = np.where(y_pred_probs>= 0.5,1,0)\n",
    "y_pred = np.reshape(y_pred, -1)\n",
    "\n",
    "# Transform the numpy image array back to a 1D list\n",
    "X_temp = []\n",
    "for i, image in enumerate(val_images):\n",
    "    X_temp.append(X[i,:,:,0])\n",
    "X = X_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7e5ad",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31d95b",
   "metadata": {},
   "source": [
    "### The following lines should not be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182e4e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Pred: Fluten  Pred: Normal\n",
      "True: Fluten            52             0\n",
      "True: Normal             0            48\n"
     ]
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "cfmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred), \n",
    "    index=['True: Fluten', 'True: Normal'], \n",
    "    columns=['Pred: Fluten', 'Pred: Normal']\n",
    ")\n",
    "print(cfmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a8ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate= 0.000\n"
     ]
    }
   ],
   "source": [
    "# Compute the error rate\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print('Error rate= %.3f' % (1-accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09effc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC = 1.000\n"
     ]
    }
   ],
   "source": [
    "# Compute the ROC AUC\n",
    "roc_auc = roc_auc_score(y_true, y_pred_probs)\n",
    "print('ROC AUC = %.3f' % (roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04769913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYNElEQVR4nO3df7RdZX3n8fcnEAhCQCRxdPgVsPEHVSuQwShj1WIV0IF2RH5UpqVFmapYHdA1tLjQorVjqXZJS6tRWaiDItLqShVlWgviKAGCIJAgrjSKhB9DGlNEEUnId/7YO/X0cnPvibn7XO/d79dad92993nO3t+dC/dz937Ofp5UFZKk/poz3QVIkqaXQSBJPWcQSFLPGQSS1HMGgST13M7TXcD2WrBgQS1atGi6y5CkGeWmm276l6paON5rMy4IFi1axMqVK6e7DEmaUZLcta3XvDUkST1nEEhSzxkEktRzBoEk9ZxBIEk911kQJLk4yQNJbt/G60lyYZI1SW5NclhXtUiStq3LK4JLgKMneP0YYHH7dQbwNx3Wwk13beSiq9dw010buzyMJHWiy99hnT1HUFXXJlk0QZPjgU9UMw72iiRPTPLUqrpvqmu56a6NnLzsOjY9VswJPPMp85k/b+5UH0aSOvHQI5v49v0PUQW7zp3Dpa9byuEH7j1l+5/OPoJ9gbsH1te12x4nyRlJViZZuX79+u0+0Iq1G9j0WDPvwpaCHz6y+ecoV5Kmxw8f2cyWggI2bd7CirUbpnT/M+LJ4qpaBiwDWLJkyXbPpLP04H2YkyYE5s2dwwdPPnRK01SSunTTXRt57UdXsGnzFubuPIelB+8zpfufziC4B9h/YH2/dtuUO/zAvTngSU/gBz9+lHOOeZYhIGlGOfzAvbn0dUtZsXYDSw/eZ8p/h01nECwHzkxyGfB84MEu+gegSdPv/+BhthSc/4VVPOMp8w0DSTPK4Qfu3dnvrc6CIMmngZcAC5KsA94JzAWoqg8BVwLHAmuAh4Hf7aqWFWs3sKW9obT1/ppBIEmNLj81dMokrxfwpq6OP2iwj6CL+2uSNJPNiM7iHXX4gXvzzKfM54ePbLajWJLG6EUQAMyfN5f58+YaApI0hmMNSVLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9ZxBIEk9ZxBIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9ZxBIEk9ZxBIUs8ZBJLUcwaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSz3UaBEmOTnJnkjVJzhnn9QOSXJ3k5iS3Jjm2y3okSY/XWRAk2Qm4CDgGOAQ4JckhY5q9A7i8qg4FTgb+uqt6JEnj6/KK4AhgTVWtrapHgcuA48e0KWDPdnkv4N4O65EkjaPLINgXuHtgfV27bdC7gFOTrAOuBN483o6SnJFkZZKV69ev76JWSeqt6e4sPgW4pKr2A44FPpnkcTVV1bKqWlJVSxYuXDjyIiVpNusyCO4B9h9Y36/dNuh04HKAqroOmAcs6LAmSdIYXQbBjcDiJAcl2YWmM3j5mDbfB44CSPIsmiDw3o8kjVBnQVBVm4EzgauAO2g+HbQqyflJjmubnQ28Psm3gE8Dp1VVdVWTJOnxdu5y51V1JU0n8OC28waWVwNHdlmDJGli091ZLEmaZgaBJPWcQSBJPWcQSFLPGQSS1HMGgST1nEEgST1nEEhSzxkEktRzBoEk9dzQQZDkCV0WIkmaHpMGQZIXJlkNfLtd/5UkTikpSbPEMFcEfwG8AtgAUFXfAn61y6IkSaMz1K2hqrp7zKbHOqhFkjQNhhmG+u4kLwQqyVzgLTTzC0iSZoFhrgh+H3gTzcTz9wDPA97YYU2SpBEa5orgGVX12sENSY4Evt5NSZKkURrmiuAvh9wmSZqBtnlFkOQFwAuBhUnOGnhpT2CnrguTJI3GRLeGdgH2aNvMH9j+Q+CELouSJI3ONoOgqr4KfDXJJVV11whrkiSN0DCdxQ8nuQD4ZWDe1o1V9WudVSVJGplhOosvpRle4iDgj4HvATd2WJMkaYSGCYJ9qupjwKaq+mpV/R7g1YAkzRLD3Bra1H6/L8krgXuBJ3VXkiRplIYJgvck2Qs4m+b5gT2Bt3ZZlCRpdCYNgqr6Qrv4IPBS+LcniyVJs8BED5TtBJxIM8bQl6vq9iSvAv4I2A04dDQlSpK6NNEVwceA/YEbgAuT3AssAc6pqs+PoDZJ0ghMFARLgOdW1ZYk84D7gadV1YbRlCZJGoWJPj76aFVtAaiqR4C12xsCSY5OcmeSNUnO2UabE5OsTrIqyae2Z/+SpB030RXBM5Pc2i4HeFq7HqCq6rkT7bjtY7gI+HVgHXBjkuVVtXqgzWLgD4Ejq2pjkifvwLlIkn4OEwXBs3Zw30cAa6pqLUCSy4DjgdUDbV4PXFRVGwGq6oEdPKYkaTtNNOjcjg40ty8wONfxOuD5Y9o8HSDJ12mGtn5XVX157I6SnAGcAXDAAQfsYFmSpEFDTV7foZ2BxcBLgFOAjyR54thGVbWsqpZU1ZKFCxeOtkJJmuW6DIJ7aD5+utV+7bZB64DlVbWpqr4LfIcmGCRJIzJUECTZLckztnPfNwKLkxyUZBfgZGD5mDafp7kaIMkCmltFa7fzOJKkHTBpECT5L8AtwJfb9eclGfsL/XGqajNwJnAVcAdweVWtSnJ+kuPaZlcBG5KsBq4G3u5zCpI0WsMMOvcumk8AXQNQVbckOWiYnVfVlcCVY7adN7BcwFntlyRpGgxza2hTVT04Zlt1UYwkafSGuSJYleS3gJ3aB8D+APhGt2VJkkZlmCuCN9PMV/xT4FM0w1G/tcOaJEkjNMwVwTOr6lzg3K6LkSSN3jBXBO9PckeSdyd5ducVSZJGatIgqKqX0sxMth74cJLbkryj88okSSMx1ANlVXV/VV0I/D7NMwXnTfwOSdJMMcwDZc9K8q4kt9FMXv8NmuEiJEmzwDCdxRcDnwFeUVX3dlyPJGnEJg2CqnrBKAqRJE2PbQZBksur6sT2ltDgk8RDzVAmSZoZJroieEv7/VWjKESSND222VlcVfe1i2+sqrsGv4A3jqY8SVLXhvn46K+Ps+2YqS5EkjQ9JuojeAPNX/4HJ7l14KX5wNe7LkySNBoT9RF8CvgS8KfAOQPbH6qqH3RalSRpZCYKgqqq7yV509gXkjzJMJCk2WGyK4JXATfRfHw0A68VcHCHdUmSRmSbQVBVr2q/DzUtpSRpZhpmrKEjk+zeLp+a5ANJDui+NEnSKAzz8dG/AR5O8ivA2cA/A5/stCpJ0sgMEwSbq6qA44G/qqqLaD5CKkmaBYYZffShJH8I/DfgRUnmAHO7LUuSNCrDXBGcRDNx/e9V1f00cxFc0GlVkqSRGWaqyvuBS4G9krwKeKSqPtF5ZZKkkRjmU0MnAjcArwFOBK5PckLXhUmSRmOYPoJzgf9UVQ8AJFkI/CNwRZeFSZJGY5g+gjlbQ6C1Ycj3SZJmgGGuCL6c5Crg0+36ScCV3ZUkSRqlYeYsfnuS/wr853bTsqr6XLdlSZJGZaL5CBYDfw48DbgNeFtV3TOqwiRJozHRvf6LgS8Ar6YZgfQvt3fnSY5OcmeSNUnOmaDdq5NUkiXbewxJ0o6Z6NbQ/Kr6SLt8Z5Jvbs+Ok+wEXEQz1eU64MYky6tq9Zh284G3ANdvz/4lSVNjoiCYl+RQfjYPwW6D61U1WTAcAaypqrUASS6jGa9o9Zh27wbeB7x9O2uXJE2BiYLgPuADA+v3D6wX8GuT7Htf4O6B9XXA8wcbJDkM2L+qvphkm0GQ5AzgDIADDnAEbEmaShNNTPPSLg/cDl73AeC0ydpW1TJgGcCSJUuqy7okqW+6fDDsHmD/gfX92m1bzQeeDVyT5HvAUmC5HcaSNFpdBsGNwOIkByXZBTgZWL71xap6sKoWVNWiqloErACOq6qVHdYkSRqjsyCoqs3AmcBVwB3A5VW1Ksn5SY7r6riSpO0z6ZPFSQK8Fji4qs5v5yt+SlXdMNl7q+pKxgxHUVXnbaPtS4aqWJI0pYa5Ivhr4AXAKe36QzTPB0iSZoFhBp17flUdluRmgKra2N7zlyTNAsNcEWxqnxIu+Lf5CLZ0WpUkaWSGCYILgc8BT07yJ8D/Bd7baVWSpJEZZhjqS5PcBBxFM7zEb1TVHZ1XJkkaiWE+NXQA8DDw94Pbqur7XRYmSRqNYTqLv0jTPxBgHnAQcCfwyx3WJUkakWFuDT1ncL0dKO6NnVUkSRqp7X6yuB1++vmTNpQkzQjD9BGcNbA6BzgMuLeziiRJIzVMH8H8geXNNH0Gf9tNOZKkUZswCNoHyeZX1dtGVI8kacS22UeQZOeqegw4coT1SJJGbKIrghto+gNuSbIc+Czw460vVtXfdVybJGkEhukjmAdsoJmjeOvzBAUYBJI0C0wUBE9uPzF0Oz8LgK2cN1iSZomJgmAnYA/+fQBsZRBI0iwxURDcV1Xnj6wSSdK0mOjJ4vGuBCRJs8xEQXDUyKqQJE2bbQZBVf1glIVIkqbHdg86J0maXQwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnOg2CJEcnuTPJmiTnjPP6WUlWJ7k1yVeSHNhlPZKkx+ssCNr5ji8CjgEOAU5JcsiYZjcDS6rqucAVwJ91VY8kaXxdXhEcAaypqrVV9ShwGXD8YIOqurqqHm5XVwD7dViPJGkcXQbBvsDdA+vr2m3bcjrwpfFeSHJGkpVJVq5fv34KS5Qk/UJ0Fic5FVgCXDDe61W1rKqWVNWShQsXjrY4SZrlhpm8/ud1D7D/wPp+7bZ/J8nLgHOBF1fVTzusR5I0ji6vCG4EFic5KMkuwMnA8sEGSQ4FPgwcV1UPdFiLJGkbOguCqtoMnAlcBdwBXF5Vq5Kcn+S4ttkFwB7AZ5PckmT5NnYnSepIl7eGqKorgSvHbDtvYPllXR5fkjS5X4jOYknS9DEIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknrOIJCknjMIJKnnDAJJ6jmDQJJ6ziCQpJ4zCCSp5wwCSeq5ToMgydFJ7kyyJsk547y+a5LPtK9fn2RRl/VIkh6vsyBIshNwEXAMcAhwSpJDxjQ7HdhYVb8E/AXwvq7qeeiRTdzzrz/hprs2dnUISZqRurwiOAJYU1Vrq+pR4DLg+DFtjgc+3i5fARyVJFNdyE13beTb9z/Euo0/4bUfXWEYSNKALoNgX+DugfV17bZx21TVZuBBYJ+xO0pyRpKVSVauX79+uwtZsXYDVc3yps1bWLF2w3bvQ5JmqxnRWVxVy6pqSVUtWbhw4Xa/f+nB+7Dr3DnsFJi78xyWHvy4rJGk3tq5w33fA+w/sL5fu228NuuS7AzsBUz5n+uHH7g3l75uKSvWbmDpwftw+IF7T/UhJGnG6jIIbgQWJzmI5hf+ycBvjWmzHPgd4DrgBOCfqrbexJlahx+4twEgSePoLAiqanOSM4GrgJ2Ai6tqVZLzgZVVtRz4GPDJJGuAH9CEhSRphLq8IqCqrgSuHLPtvIHlR4DXdFmDJGliM6KzWJLUHYNAknrOIJCknjMIJKnn0tGnNTuTZD1w18/59gXAv0xhOTOB59wPnnM/7Mg5H1hV4z6RO+OCYEckWVlVS6a7jlHynPvBc+6Hrs7ZW0OS1HMGgST1XN+CYNl0FzANPOd+8Jz7oZNz7lUfgSTp8fp2RSBJGsMgkKSem5VBkOToJHcmWZPknHFe3zXJZ9rXr0+yaBrKnFJDnPNZSVYnuTXJV5IcOB11TqXJznmg3auTVJIZ/1HDYc45yYntz3pVkk+NusapNsR/2wckuTrJze1/38dOR51TJcnFSR5Icvs2Xk+SC9t/j1uTHLbDB62qWfVFM+T1PwMHA7sA3wIOGdPmjcCH2uWTgc9Md90jOOeXAk9ol9/Qh3Nu280HrgVWAEumu+4R/JwXAzcDe7frT57uukdwzsuAN7TLhwDfm+66d/CcfxU4DLh9G68fC3wJCLAUuH5HjzkbrwiOANZU1dqqehS4DDh+TJvjgY+3y1cARyXJCGucapOec1VdXVUPt6sraGaMm8mG+TkDvBt4H/DIKIvryDDn/HrgoqraCFBVD4y4xqk2zDkXsGe7vBdw7wjrm3JVdS3N/CzbcjzwiWqsAJ6Y5Kk7cszZGAT7AncPrK9rt43bpqo2Aw8CM3ki42HOedDpNH9RzGSTnnN7ybx/VX1xlIV1aJif89OBpyf5epIVSY4eWXXdGOac3wWcmmQdzfwnbx5NadNme/9/n1SnE9PoF0+SU4ElwIunu5YuJZkDfAA4bZpLGbWdaW4PvYTmqu/aJM+pqn+dzqI6dgpwSVW9P8kLaGY9fHZVbZnuwmaK2XhFcA+w/8D6fu22cdsk2ZnmcnLDSKrrxjDnTJKXAecCx1XVT0dUW1cmO+f5wLOBa5J8j+Ze6vIZ3mE8zM95HbC8qjZV1XeB79AEw0w1zDmfDlwOUFXXAfNoBmebrYb6/317zMYguBFYnOSgJLvQdAYvH9NmOfA77fIJwD9V2wszQ016zkkOBT5MEwIz/b4xTHLOVfVgVS2oqkVVtYimX+S4qlo5PeVOiWH+2/48zdUASRbQ3CpaO8Iap9ow5/x94CiAJM+iCYL1I61ytJYDv91+emgp8GBV3bcjO5x1t4aqanOSM4GraD5xcHFVrUpyPrCyqpYDH6O5fFxD0ylz8vRVvOOGPOcLgD2Az7b94t+vquOmregdNOQ5zypDnvNVwMuTrAYeA95eVTP2anfIcz4b+EiS/0HTcXzaTP7DLsmnacJ8Qdvv8U5gLkBVfYimH+RYYA3wMPC7O3zMGfzvJUmaArPx1pAkaTsYBJLUcwaBJPWcQSBJPWcQSFLPGQT6hZTksSS3DHwtmqDtj6bgeJck+W57rG+2T6hu7z4+muSQdvmPxrz2jR2tsd3P1n+X25P8fZInTtL+eTN9NE51z4+P6hdSkh9V1R5T3XaCfVwCfKGqrkjycuDPq+q5O7C/Ha5psv0m+Tjwnar6kwnan0Yz6uqZU12LZg+vCDQjJNmjnUfhm0luS/K4kUaTPDXJtQN/Mb+o3f7yJNe17/1sksl+QV8L/FL73rPafd2e5K3ttt2TfDHJt9rtJ7Xbr0myJMn/AnZr67i0fe1H7ffLkrxyoOZLkpyQZKckFyS5sR1j/r8P8c9yHe1gY0mOaM/x5iTfSPKM9knc84GT2lpOamu/OMkNbdvxRmxV30z32Nt++TXeF81Tsbe0X5+jeQp+z/a1BTRPVW69ov1R+/1s4Nx2eSea8YYW0Pxi373d/j+B88Y53iXACe3ya4DrgcOB24DdaZ7KXgUcCrwa+MjAe/dqv19DO+fB1poG2myt8TeBj7fLu9CMIrkbcAbwjnb7rsBK4KBx6vzRwPl9Fji6Xd8T2Lldfhnwt+3yacBfDbz/vcCp7fITacYi2n26f95+Te/XrBtiQrPGT6rqeVtXkswF3pvkV4EtNH8J/wfg/oH33Ahc3Lb9fFXdkuTFNJOVfL0dWmMXmr+kx3NBknfQjFNzOs34NZ+rqh+3Nfwd8CLgy8D7k7yP5nbS17bjvL4EfDDJrsDRwLVV9ZP2dtRzk5zQttuLZrC47455/25JbmnP/w7gHwbafzzJYpphFuZu4/gvB45L8rZ2fR5wQLsv9ZRBoJnitcBC4PCq2pRmRNF5gw2q6to2KF4JXJLkA8BG4B+q6pQhjvH2qrpi60qSo8ZrVFXfSTPXwbHAe5J8parOH+YkquqRJNcArwBOoploBZrZpt5cVVdNsoufVNXzkjyBZvydNwEX0kzAc3VV/WbbsX7NNt4f4NVVdecw9aof7CPQTLEX8EAbAi8FHjfncpp5mP9fVX0E+CjNdH8rgCOTbL3nv3uSpw95zK8Bv5HkCUl2p7mt87Uk/xF4uKr+N81gfuPNGbupvTIZz2doBgrbenUBzS/1N2x9T5Knt8ccVzWzzf0BcHZ+NpT61qGITxto+hDNLbKtrgLenPbyKM2otOo5g0AzxaXAkiS3Ab8NfHucNi8BvpXkZpq/tj9YVetpfjF+OsmtNLeFnjnMAavqmzR9BzfQ9Bl8tKpuBp4D3NDeonkn8J5x3r4MuHVrZ/EY/4dmYqB/rGb6RWiCazXwzTSTln+YSa7Y21pupZmY5c+AP23PffB9VwOHbO0sprlymNvWtqpdV8/58VFJ6jmvCCSp5wwCSeo5g0CSes4gkKSeMwgkqecMAknqOYNAknru/wPTc5+SX4yOkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curve\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_true, y_pred_probs)\n",
    "# Plot the ROC curve for the model\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a73426",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76ffe9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Image':val_images,'Label':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8d841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "res_dict['ER'] = 1-round(accuracy,3)\n",
    "res_dict['ROC'] = roc_auc\n",
    "res_dict['FP'] = int(cfmtx['Pred: Fluten'].iloc[1])\n",
    "res_dict['FN'] = int(cfmtx['Pred: Normal'].iloc[0])\n",
    "res_dict['TIME'] = int(comp_time)\n",
    "\n",
    "with open('results_metrics.json', 'w') as fp:\n",
    "    json.dump(res_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70356ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
